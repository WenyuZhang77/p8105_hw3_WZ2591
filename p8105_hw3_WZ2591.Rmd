---
title: "p8105_hw2_WZ2591"
author: "Wenyu Zhang"
date: "10/17/2021"
output: github_document
---

```{r}
library(tidyverse)
```

# Problem 1

load the data from the p8105.datasets

```{r}
library(p8105.datasets)
data("instacart")
```

## Do some exploration of this dataset

Size of the data: The dataset contains `r nrow(instacart)` observations and `r ncol(instacart)` variables.
```{r, include=FALSE}
nrow(instacart)
ncol(instacart)
skimr::skim(instacart)
```

Structure of the data: The data is about the information of online grocery orders from Instacart users. Each row represent one order of one product from Instacart users. The dataset have 15 variables: `r names(instacart)` and 4 character variables: eval_set, product_name, aisle and department.

## Describing some key variables, and giving illstrative examples of observations

**1.**
`reordered` means the product is been reordered or not. 

The mean value of `reordered` is `r mean(pull(instacart, reordered))`, and it means about 60% products are reordered.

```{r, include=FALSE}
mean(pull(instacart, reordered))
```

**2.** 
`order_hour_of_day`: records the time that the order was placed.

It shows most orders are placed at `r names(sort(table(pull(instacart, order_hour_of_day)),decreasing=TRUE))[1]`, which is at 2pm

```{r, include=FALSE}
names(sort(table(pull(instacart, order_hour_of_day)),decreasing = TRUE))[1]
```

**3.** 
`days_since_prior_order`: represents the time since the last order.

The mean value of `days_since_prior_order` is `r mean(pull(instacart, days_since_prior_order))`, which means people usually orders again after 17 days.

```{r, include=FALSE}
mean(pull(instacart, days_since_prior_order))
```

**4.** 
`product_name`: reprensets the name of product.

`r names(sort(table(pull(instacart, product_name)),decreasing=TRUE))[1]` is the product that users order most.

```{r, include=FALSE}
names(sort(table(pull(instacart, product_name)),decreasing = TRUE))[1]
```

**illstrative examples of observations** 

This is the data of the second row. It tells us that a users placed a order of Organic 4% Milk Fat Whole Milk Cottage Cheese from other creams cheeses aisle, which is 108 aisle from the department of dairy eggs. The order was placed in 10 am Thursday, and it is 9 days since prior order. 

```{r}
instacart[2,] %>% knitr::kable()
```

## Answer the following (commenting on the results of each):

### How many aisles are there, and which aisles are the most items ordered from?

There are `r length(unique(pull(instacart, aisle)))` aisles and the most items are ordered form `r names(sort(table(pull(instacart, aisle)),decreasing=TRUE))[1]`

```{r, results='hide'}
length(unique(pull(instacart, aisle)))
names(sort(table(pull(instacart, aisle)),decreasing = TRUE))[1]
```

### Make a plot that shows the number of items ordered in each aisle

```{r}
aisle = 
  instacart %>% 
  count(aisle, name = 'number_of_items') %>%
  filter(number_of_items > 10000) %>% 
  ggplot(aes(reorder(aisle, number_of_items), x = number_of_items)) + 
  geom_point() + 
  labs(
    title = "the number of items ordered 
    in each aisle with more than 10000 items ordered",
    x = "Number of items ordered in each aisle",
    y = "Aisle name",
    caption = "the data was loaded from the p8105.datasets"
  )

aisle
```

### Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. 

```{r}
Three_pop_items = 
  instacart %>%
  group_by(aisle) %>%
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits"
         ) %>%
  count(product_name, name = 'number_of_ordered_time') %>%
  top_n(n = 3, wt = number_of_ordered_time) %>% 
  arrange(desc(number_of_ordered_time)) %>%
  rename(
    'aisle name' = aisle, 
    'three most popular items in this aisle' = product_name, 
    'number of ordered time' = number_of_ordered_time
    ) %>% 
  knitr::kable(caption = "three most popular items 
               in each of the aisles baking ingredients, 
               dog food care, and packaged vegetables fruits")

Three_pop_items
```

### Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
mean_hour_apples_icecream = 
  instacart %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  select(order_dow, order_hour_of_day, product_name) %>%
  group_by(order_dow, product_name) %>%
  summarise(mean_hours_of_the_day = mean(order_hour_of_day)) %>%
  pivot_wider(names_from = 'order_dow',
              values_from = 'mean_hours_of_the_day'
              ) %>% 
  rename(`Sunday` = `0`, 
         `Monday` = `1`, 
         `Tuesday` = `2`, 
         `Wednesday` = `3`, 
         `Thursday` = `4`, 
         `Friday` = `5`, 
         `Saturday` = `6`) %>% 
  knitr::kable(caption = "the mean hour of the day 
               at which Pink Lady Apples 
               and Coffee Ice Cream are ordered on each day of the week")

mean_hour_apples_icecream
```

# Problem 2

load the data from the p8105.datasets

```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

## Clean the data

```{r}
brfss_clean =
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  select(-locationabbr) %>% 
  separate(locationdesc, into = c("state", "county"), sep = " - ") %>% 
  filter(topic == 'Overall Health',
         response %in% c('Poor', 
                         'Fair', 
                         'Good', 
                         'Very good', 
                         'Excellent')) %>%
  mutate(response = factor(response, levels = c('Poor', 
                                                'Fair', 
                                                'Good', 
                                                'Very good', 
                                                'Excellent'), 
                           ordered = TRUE)) %>% 
  arrange(response)


brfss_clean
```

## Answer the following questions:

### 1. In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r, message=FALSE}
locations_2002_2010 = 
  brfss_clean %>% 
  filter(year == 2002 | year == 2010) %>% 
  group_by(state, year) %>% 
  summarise(observed = n_distinct(county)) %>% 
  filter(observed >= 7) %>%
  pivot_wider(
    names_from = year,
    values_from = observed) 

locations_2002_2010
```

## 2. Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state

```{r, message=FALSE}
excellent_response = 
  brfss_clean %>% 
  filter(response == "Excellent") %>%
  select(year, state, data_value) %>% 
  group_by(year, state) %>% 
  summarise(average_data_value = mean(data_value))

excellent_response
```

```{r, message=FALSE}
excellent_response_plot = 
  excellent_response %>% 
  ggplot(aes(x = year, y = average_data_value, color = state)) +
  geom_line() +
  labs(
    title = "the average value over time within a state",
    caption = "Data from brfss_smart2010")

excellent_response_plot
```

## 3. Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r}
distribution = 
  brfss_clean %>% 
  filter(year == 2006 | year == 2010,
         state == 'NY') %>%
  select(year, state, county, response, data_value) 
```

```{r}
distribution_plot = 
  distribution %>%
  ggplot(aes(x = data_value, fill = response)) +
  geom_density() +
  facet_grid(. ~ year) +
  labs(title = "distribution of data_value 
       for responses (“Poor” to “Excellent”) among locations 
       in NY State in years 2006, and 2010",
       x = "data value of responses",
       y = "Density of data value") +
  scale_fill_manual(values = alpha(terrain.colors(5), 0.5))

distribution_plot
```

# Problem 3

## Load, tidy, and otherwise wrangle the data.

```{r}
accel_data = 
  read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekday_or_weekend = case_when(
      day == "Monday" ~ "weekday",
      day == "Tuesday" ~ "weekday",
      day == "Wednesday" ~ "weekday",
      day == "Thursday" ~ "weekday",
      day == "Friday" ~ "weekday",
      day == "Saturday" ~ "weekend",
      day == "Sunday" ~ "weekend")
  ) %>% 
  mutate(day = factor(day, levels = 
                        c("Monday", 
                          "Tuesday", 
                          "Wednesday", 
                          "Thursday", 
                          "Friday", 
                          "Saturday",  
                          "Sunday"))) %>% 
  select(day_id, day, weekday_or_weekend, week, everything()) %>% 
  pivot_longer(activity_1:activity_1440,
    names_to = "activity_minutes",
    names_prefix = "activity_",
    values_to = "activity_counts") %>% 
  mutate(
    week = as.factor(week), 
    weekday_or_weekend = as.factor(weekday_or_weekend),
    activity_minutes = as.numeric(activity_minutes)
  ) %>% 
  arrange(week)

accel_data    
```

## Describe the resulting dataset

```{r, include=FALSE}
nrow(accel_data)
ncol(accel_data)
skimr::skim(accel_data)
```

The dataset contains `r nrow(accel_data)` observations and `r ncol(accel_data)` variables.The variables are `r names(accel_data)`

`week`: to see which week of accelerometer data was collected on a 63-year-old male with BMI of 25

`day_id`: day identifier

 `day`: to see which day that the data collected in the week

`weekday_weekend`: to see the day is whether weekday or weekend

`activity_minutes`: count for each minute of a 24-hour day starting at midnight

`acitvity_counts`: accelerometer value in each activity_minutes

## Traditional analyses of accelerometer data focus on the total activity over the day.

```{r}
accel_data_analysis =
  accel_data %>% 
  group_by(week, day) %>% 
  summarise(total_activity = sum(activity_counts)) %>% 
   pivot_wider(
  names_from = "day", 
  values_from = "total_activity") %>%
  knitr::kable(caption = "A total activity counts for each day in 5 week")

accel_data_analysis
```

**Are any trends apparent?**
Normally, the accelerometer value in weekend is lower than the value in weekday. In saturdays of week 4 and week 5, the accelerometer value is only 1440, this is probability because patients forget to wear the accelerometer.

## Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week.

```{r}
activity_time_plot = 
  accel_data %>% 
  ggplot(aes(
         x = activity_minutes / 60,
         y = activity_counts,
         color = day)) +
  scale_x_continuous(
    breaks = c(0, 3, 6, 9, 12, 15, 18, 21, 24), 
    labels = c("00:00", 
               "03:00", 
               "06:00", 
               "09:00", 
               "12:00", 
               "15:00", 
               "18:00", 
               "21:00", 
               "24:00"), 
    limits = c(0, 24)) +
  geom_line(aes(color = day)) +
  labs(title = "the 24-hour activity time courses for each day", 
       x = "24-hour activity time", 
       y = "activity value",
       caption = "Data from accel_data.csv") +
  scale_color_hue(name = "Day of week")

activity_time_plot
```

We can see from the plot, the peak of activity for this male is around 12:00 and 19:30 - 21:00.

